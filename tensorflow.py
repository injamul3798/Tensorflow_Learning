# -*- coding: utf-8 -*-
"""Tensorflow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kxg2v6kjc9zOSF-JRy8s9kzocKnqaCA4

This short introduction uses Keras to:

1. Load a prebuilt dataset.
2. Build a neural network machine learning model that classifies images.
3. Train this neural network.
4. Evaluate the accuracy of the model.
"""

import tensorflow as tf
print('Tensorflow version : ',tf.__version__)

"""## Load a dataset
Load and prepare the MNIST dataset. The pixel values of the images range from 0 through 255. Scale these values to a range of 0 to 1 by dividing the values by 255.0. This also converts the sample data from integers to floating-point numbers:


The dataset is divided into two parts: the training set and the test set.
1. x_train and y_train are the training data and labels.
2. x_test and y_test are the test data and labels.
"""

mnsit = tf.keras.datasets.mnist
(x_train,y_train),(x_test,y_test) = mnsit.load_data()
x_train = x_train / 255.0
x_test = x_test / 255.0
x_train



model  = tf.keras.models.Sequential([
    #The Flatten layer converts each 28x28 image into a 1D array of 784 elements (28*28).
    tf.keras.layers.Flatten(input_shape=(28,28)),
    #The Dense layer is a fully connected layer with 128 neurons.
    tf.keras.layers.Dense(128,activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10)
])

model.summary()

"""For each example, the model returns a vector of logits or log-odds scores, one for each class."""

predictions = model(x_train[:1]).numpy()
predictions

"""The tf.nn.softmax function converts these logits to probabilities for each class:"""

tf.nn.softmax(predictions).numpy()

"""# Now define a loss function
The loss function takes a vector of ground truth values and a vector of logits and returns a scalar loss for each example. This loss is equal to the negative log probability of the true class: The loss is zero if the model is sure of the correct class.
"""

loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

"""This untrained model gives probabilities close to random (1/10 for each class), so the initial loss should be close to -tf.math.log(1/10) ~= 2.3."""

loss_function(y_train[:1],predictions).numpy()

"""Before you start training, configure and compile the model using Keras Model.compile. Set the optimizer class to adam, set the loss to the loss_fn function you defined earlier, and specify a metric to be evaluated for the model by setting the metrics parameter to accuracy."""

model.compile(
    optimizer ='adam',
    loss = loss_function,
    metrics = [
        'accuracy',
       # tf.keras.metrics.Precision(name='precision'),
       # tf.keras.metrics.Recall(name='recall'),
        ]
)

"""Train and Evalutation"""

model.fit(x_train,y_train,epochs=5,)

model.evaluate(x_test,y_test,verbose=2)